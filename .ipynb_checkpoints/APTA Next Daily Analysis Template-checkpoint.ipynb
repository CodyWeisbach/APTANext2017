{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Analysis of the APTA Next 2017 Conference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'll import the libraries that are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pymongo\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EP3 East Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling\n",
    "Before I can analyze anything, I need to get the data out of my database and organize it into a form that can easily be analyzed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'll make a connection to my database. Everything is stored in a database called MongoDB on my laptop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client_con = pymongo.MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client_con.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local_db = client_con['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local_db.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Next2017' is the collection with the data from .  \n",
    "I'll load the data into a variable called data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_set = local_db['Next2017']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I'll take a quick look at how many tweets are in there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_set.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you are wondering, this is what one tweet looks like. \n",
    "There's a ton of data in each tweet, which is one of the reasons I'm interested in this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print data_set.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to change the format of the data to something easier to look at.\n",
    "First, I'll make the database collection into a list of dictionaries, which is easier to work with in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_data = list(data_set.find())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I'll make that list into a dataframe, which looks more like a spread sheet\n",
    "I'm going to make it a function that I can use over again for the west data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_results(results):\n",
    "    id_list = [tweet['id'] for tweet in results]\n",
    "    data_set = pd.DataFrame(id_list, columns = [\"id\"])\n",
    "    \n",
    "    data_set['user'] = [tweet['user']['screen_name'] for tweet in results]\n",
    "    data_set[\"text\"] = [tweet['text'] for tweet in results]\n",
    "    data_set[\"retweet_count\"] = [tweet['retweet_count'] for tweet in results]\n",
    "    data_set[\"favorite_count\"] = [tweet['favorite_count'] for tweet in results]\n",
    "    data_set[\"created_at\"] = [tweet['created_at'] for tweet in results]\n",
    "    \n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll use that function to process my data into the dataframe and store it in a variable df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_east = process_results(tweet_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at it.  \n",
    "First I'll check the length, hopefully it's the same as my number of records above.  \n",
    "Then I'll look at the top 5 rows and the bottom 5 rows to make sure it all looks right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df_east)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_east.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_east.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It all looks good.  \n",
    "Now I need to change the 'created_at' column to a different format that will make is easier for me to split up the data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_east['created_at'] = pd.to_datetime(df_east['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_east.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll make a new column that adds retweets plus favorites. That will give some idea of the importance of a particular tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_east['important_tweets'] = df_east['retweet_count'] + df_east['favorite_count']\n",
    "df_east.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Next, we to adjust the data set to only look at origional tweets, not retweets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I'll make a column looking at whether or not is was retweeted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_east['retweeted'] = df_east['text'].str.startswith('RT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_east.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Tweets\n",
    "Now I'll include only the origional tweets in the data set. \n",
    "Then I'll look at how many we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_east = df_east[df_east['retweeted'] == False]\n",
    "len(df_east)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Retweets and Total Favorites\n",
    "Next, let's look at some numbers from the full conference data set.   \n",
    "We have total tweets (664). Let's also look at total retweets and total favorites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "east_retweets = df_east['retweet_count'].sum()\n",
    "print east_retweets\n",
    "east_favorites = df_east['favorite_count'].sum()\n",
    "print east_favorites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 Tweets from \n",
    "Now let's look at the 10 most importatn tweets.  \n",
    "First we'll sort the data by \"important_tweets\" to with highest number on top.  \n",
    "Then we'll show the top 10\n",
    "If you want to see the origional tweet, just go to http://twitter.com/statuses/ and put the tweet ID at the end after that last \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_east = df_east.sort_values(['important_tweets'], ascending = False)\n",
    "sorted_east.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud\n",
    "The Last step for the full conference analysis is the Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = \" \".join(df_east[\"text\"].values)\n",
    "no_url_no_tag = \" \".join([word for word in text.split(' ')\n",
    "                        if 'http' not in word\n",
    "                        and not word.startswith('@')\n",
    "                        and word != 'RT'\n",
    "                        and word != 'APTANEXT'])\n",
    "wc = WordCloud(background_color=\"white\", font_path=\"/Library/Fonts/Verdana.ttf\", stopwords=STOPWORDS, width=500, height=300)\n",
    "wc.generate(no_url_no_tag)\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"APTA Next 2017\")\n",
    "plt.savefig('Next2017.png', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That's it!  \n",
    "Hopefully you found this interesting.  \n",
    "If you did, let me know at [@CodyWeisbach](http://twitter.com/codyweisbach) on Twitter and I'll keep it up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
